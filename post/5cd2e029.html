<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.1.0">

<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="0iM1o-efKbqYlCu_zW-bU1OIupeemwYcmetguLhpRj4">
  <meta name="baidu-site-verification" content="code-oiXRLjFejQ">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.0.0/css/all.min.css" integrity="sha256-jTIdiMuX/e3DGJUGwl3pKSxuc6YOuqtJYkM0bGQESA4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"pingpinggray.top","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.10.1","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"manual"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"waline","storage":true,"lazyload":false,"nav":{"waline":{"order":-1},"gitalk":{"order":-2}},"activeClass":"waline"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>



<link rel="canonical" href="https://pingpinggray.top/post/5cd2e029.html">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://pingpinggray.top/post/5cd2e029.html","path":"post/5cd2e029.html","title":"Spark"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Spark | Gray Dynasty</title>
  




<link rel="dns-prefetch" href="blog-vercel-sage.vercel.app">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Gray Dynasty" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Gray Dynasty</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%8E-MR-%E5%BC%82%E5%90%8C"><span class="nav-text">与 MR 异同</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark"><span class="nav-text">Spark</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MapReduce"><span class="nav-text">MapReduce</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84"><span class="nav-text">架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Master"><span class="nav-text">Master</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Worker"><span class="nav-text">Worker</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Driver"><span class="nav-text">Driver</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Executor"><span class="nav-text">Executor</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B5%81%E7%A8%8B"><span class="nav-text">流程</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RDD"><span class="nav-text">RDD</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E6%80%A7"><span class="nav-text">特性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-text">序列化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB"><span class="nav-text">依赖关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-text">持久化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%97%E5%AD%90"><span class="nav-text">算子</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#mapPartition"><span class="nav-text">mapPartition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#distinct"><span class="nav-text">distinct</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reduceByKey"><span class="nav-text">reduceByKey</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%B4%AF%E5%8A%A0%E5%99%A8"><span class="nav-text">累加器</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F"><span class="nav-text">广播变量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6"><span class="nav-text">任务调度</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84-1"><span class="nav-text">架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Stage-%E7%BA%A7%E8%B0%83%E5%BA%A6"><span class="nav-text">Stage 级调度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Task-%E7%BA%A7%E8%B0%83%E5%BA%A6"><span class="nav-text">Task 级调度</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5"><span class="nav-text">调度策略</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="nav-text">数据倾斜</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%98%E5%8C%96"><span class="nav-text">优化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%95%99%E5%AD%98%E8%AE%A1%E7%AE%97"><span class="nav-text">留存计算</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%8F%E8%A7%86%EF%BC%88Pviot%EF%BC%89"><span class="nav-text">透视（Pviot）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%86%E9%80%8F%E8%A7%86"><span class="nav-text">逆透视</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%80%E8%A1%8C%E6%8B%86%E5%88%86%E5%A4%9A%E8%A1%8C"><span class="nav-text">一行拆分多行</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E7%BB%84%E8%81%9A%E5%90%88"><span class="nav-text">分组聚合</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8E%92%E5%BA%8F"><span class="nav-text">排序</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0"><span class="nav-text">窗口函数</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#UDF"><span class="nav-text">UDF</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Chris Gray"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Chris Gray</p>
  <div class="site-description" itemprop="description">Chris Blog</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">100</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/ChrisGray0626" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ChrisGray0626" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://rxresu.me/r/MZbeJ3es" title="个人简历 → https:&#x2F;&#x2F;rxresu.me&#x2F;r&#x2F;MZbeJ3es" rel="noopener" target="_blank">个人简历</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://rxresu.me/r/JcVMR_6g" title="Resume → https:&#x2F;&#x2F;rxresu.me&#x2F;r&#x2F;JcVMR_6g" rel="noopener" target="_blank">Resume</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://pingpinggray.top/post/5cd2e029.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Chris Gray">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gray Dynasty">
      <meta itemprop="description" content="Chris Blog">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Spark | Gray Dynasty">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Spark
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-09-24 11:34:05" itemprop="dateCreated datePublished" datetime="2021-09-24T11:34:05+01:00">2021-09-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-04-21 11:26:15" itemprop="dateModified" datetime="2023-04-21T11:26:15+01:00">2023-04-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Technology-Stack/" itemprop="url" rel="index"><span itemprop="name">Technology_Stack</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Technology-Stack/Big-Data/" itemprop="url" rel="index"><span itemprop="name">Big_Data</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline: </span>
  
    <a title="waline" href="/post/5cd2e029.html#waline-comments" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" id="/post/5cd2e029.html" data-xid="/post/5cd2e029.html" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span id="/post/5cd2e029.html" class="post-meta-item leancloud_visitors" data-flag-title="Spark" title="Views">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="Symbols count in article">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">Symbols count in article: </span>
      <span>14k</span>
    </span>
    <span class="post-meta-item" title="Reading time">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">Reading time &asymp;</span>
      <span>12 mins.</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>Spark 延续了MapReduce 的设计思路：对数据的计算也分为Map 和Reduce 两类。但不同的是，一个 Spark 任务并不止包含一个 Map 和一个R educe，而是由一系列的 Map、Reduce 构成。这样，计算的中间结果可以高效地转给下一个计算步骤，提高算法性能。虽然 Spark 的改进看似很小，但实验结果显示，它的算法性能相比 MapReduce 提高了10～100 倍。</p>
<span id="more"></span>

<h1 id="与-MR-异同"><a href="#与-MR-异同" class="headerlink" title="与 MR 异同"></a>与 MR 异同</h1><h2 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h2><ol>
<li><p>集流批处理、交互式查询、机器学习及图计算等于一体</p>
</li>
<li><p>基于<strong>内存迭代式</strong>计算，适合低延迟、迭代运算类型作业</p>
</li>
<li><p>可以通过缓存共享 rdd、DataFrame 提升效率，尤其是SparkSQL可以将数据以列式的形式存储于内存中</p>
</li>
<li><p>中间结果支持 checkpoint ，遇错可快速恢复</p>
</li>
<li><p>支持 DAG,map 之间以 pipeline 方式运行，无需磁盘 IO</p>
</li>
<li><p><strong>多线程</strong>模型，每个 worker 节点运行一个或多个 executor 服务，每个 task 作为线程运行在 executor 中，task 间可通过<strong>内存</strong>共享资源</p>
</li>
<li><p>Spark 编程模型更灵活，支持多种语言如 java、scala、python、R，并支持丰富的 transformation 和 action 的算子</p>
</li>
</ol>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><ol>
<li><p>适合离线数据处理，不适合迭代计算、交互式处理、流式处理</p>
</li>
<li><p>中间结果需要落地，需要大量的磁盘 IO 和网络 IO 影响性能</p>
</li>
<li><p>虽然 MapReduce 中间结果可以存储于 HDFS，利用 HDFS 缓存功能，但相对 Spark 缓存功能较低效</p>
</li>
<li><p><strong>多进程</strong>模型，任务调度（频繁申请、释放资源）和启动开销大，不适合低延迟类型作业</p>
</li>
<li><p>编程不够灵活，仅支持 map 和 reduce 两种操作。</p>
</li>
</ol>
<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>Spark 集群的独立部署环境中，不需要依赖其他的资源调度框架，自身就实现了资源调度的功能。</p>
<h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2><p>一个主要负责资源的调度和分配的进程，并进行集群的监控等职责，类似于 Yarn 环境中的 RM。</p>
<h2 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h2><p>一个运行在集群中的一台服务器上的进程，由 Master 分配资源对数据进行并行的处理和计算，类似于 Yarn 环境中 NM。</p>
<h2 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h2><p>Spark 驱动器节点，用于执行 Spark 任务中的 main 方法，负责实际代码的执行工作。</p>
<ul>
<li>将用户程序转化为 Job</li>
<li>在 Executor 之间调度 Task</li>
<li>跟踪 Executor 的执行情况</li>
<li>通过 UI 展示查询运行情况</li>
</ul>
<h2 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h2><p>集群中工作节点（Worker）中的一个 JVM 进程，负责在 Spark Job 中运行具体的 Task，Task 彼此之间相互独立。</p>
<p>Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。</p>
<p>通过自身的块管理器（Block Manager）为 RDD 提供内存式存储，RDD 是直接缓存在 Executor 内的，因此任务可以在运行时充分利用缓存数据加速运算。</p>
<h3 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h3><ul>
<li><code>--num-executors </code></li>
</ul>
<h1 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h1><ol>
<li>Task 提交后，都会先启动 Driver；</li>
<li>Driver 向集群管理器注册应用程序；</li>
<li>集群管理器根据此任务的配置文件分配 Executor 并启动；</li>
<li>Driver 开始执行 main 函数，Spark 查询为懒执行，当执行到 Action 算子时开始反向推算，根据宽依赖进行 Stage 的划分，每一个 Stage 对应一个 TaskSet，TaskSet 中有多个 Task，查找可用资源 Executor 进行调度；</li>
<li>根据本地化原则，Task 会被分发到指定的 Executor 去执行，在任务执行的过程中，Executor 也会不断与 Driver 进行通信，报告任务运行情况。</li>
</ol>
<h1 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h1><p>RDD（Resilient Distributed Datasets），弹性分布式数据集。传统的 MapReduce 虽然具有自动容错、平衡负载和可拓展性的优点，但是其最大缺点是在迭代计算式的时候，要进行大量的磁盘 IO 操作，而 RDD 正是解决这一缺点的<strong>抽象方法</strong>。</p>
<p>RDD 内部的数据集合在逻辑上和物理上被划分成多个小<strong>子集合</strong>，这样的每一个子集合我们将其称为分区（Partitions），分区的个数会决定并行计算的粒度，即并行任务的个数。</p>
<p>RDD 只是数据集的抽象，分区内部并不会存储具体的数据。Partition 类内包含一个 index 成员，表示该分区在 RDD 内的索引，通过索引 + 分区号可以确定唯一数据块，再利用底层数据存储层提供的接口就能从存储介质（如：HDFS、Memory）中提取出分区对应的数据。</p>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul>
<li>弹性<ul>
<li>存储的弹性：内存与磁盘的自动切换；</li>
<li>容错的弹性：数据丢失可以自动恢复；</li>
<li>计算的弹性：计算出错重试机制；</li>
<li>分片的弹性：可根据需要重新分片。</li>
</ul>
</li>
<li>分布式：数据存储在大数据集群不同节点上</li>
<li>数据集：RDD 封装了计算逻辑，并不保存数据</li>
<li>数据抽象：RDD 是一个抽象类，需要子类具体实现</li>
<li>不可变：RDD 封装了计算逻辑，是不可以改变的，想要改变，只能产生新的 RDD，在新的 RDD 里面封装计算逻辑</li>
<li>可分区、并行计算</li>
</ul>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><h3 id="闭包检查"><a href="#闭包检查" class="headerlink" title="闭包检查"></a>闭包检查</h3><p>从计算的角度, 算子以外的代码都是在 Driver 端执行, 算子里面的代码都是在 Executor 端执行。那么在 scala 的函数式编程中，就会导致算子内经常会用到算子外的数据，这样就形成了闭包的效果，如果使用的算子外的数据无法序列化，就意味着无法传值给 Executor 端执行，就会发生错误，所以需要在执行任务计算前，检测闭包内的对象是否可以进行序列化。</p>
<h3 id="Kryo"><a href="#Kryo" class="headerlink" title="Kryo"></a>Kryo</h3><p>速度是 Serializable 的 10 倍。当 RDD 在 Shuffle 数据的时候，简单数据类型、数组和字符串类型已经有 Kryo 序列化。</p>
<p>注意：即使使用 Kryo 序列化，也要继承 Serializable 接口。</p>
<h2 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h2><ul>
<li>两个相邻 RDD 之间的关系</li>
</ul>
<h3 id="血缘关系"><a href="#血缘关系" class="headerlink" title="血缘关系"></a>血缘关系</h3><p>RDD 只支持粗粒度转换，即在大量记录上执行的单个操作。</p>
<p>将创建 RDD 的一系列 Lineage （血统）记录下来，以便恢复丢失的分区。Lineage 会记录 RDD 的元数据信息和转换行为，当该 RDD 的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p>
<h3 id="窄依赖"><a href="#窄依赖" class="headerlink" title="窄依赖"></a>窄依赖</h3><p>表示每一个父（上游） RDD 的 Partition 最多被子（下游）RDD 的一个 Partition 使用。</p>
<ul>
<li>独生子女</li>
</ul>
<h3 id="宽依赖"><a href="#宽依赖" class="headerlink" title="宽依赖"></a>宽依赖</h3><p>表示同一个父（上游）RDD 的 Partition 被多个子（下游）RDD 的 Partition 依赖，会引起 Shuffle。</p>
<ul>
<li>多生</li>
</ul>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><ul>
<li>通过 cache 或 persist 方法将前面的计算结果缓存</li>
</ul>
<p>默认情况下会把数据以缓存的形式存储在 JVM 的堆内存中。缓存有可能丢失，或者由于内存不足而被删除，但 RDD 的<strong>缓存容错机制</strong>保证了即使缓存丢失也能保证计算的正确执行。</p>
<p>由于 RDD 的各个 Partition 是相对独立的，因此只需要计算丢失的部分即可， 并不需要重算全部 Partition。 </p>
<p>Spark 会自动对一些 Shuffle 操作的中间数据做持久化操作，比如：reduceByKey。这样做是为了当一个节点 Shuffle 失败时避免重新计算整个输入。但是，在实际使用的时候，如果想重用数据，仍然建议调用 persist 或 cache。</p>
<p>遵循懒加载原则，cache 操作并不会马上被执行，必须执行 Action 操作才能触发。</p>
<h3 id="CheckPoint"><a href="#CheckPoint" class="headerlink" title="CheckPoint"></a>CheckPoint</h3><ul>
<li>将 RDD 中间结果写入磁盘</li>
</ul>
<p>由于血缘依赖过长会造成容错成本过高，如果检查点之后有节点出现问题，可以从检查点开始重做血缘，减少了开销。</p>
<p>遵循懒加载原则，checkpoint 操作并不会马上被执行，必须执行 Action 操作才能触发。</p>
<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ul>
<li>Cache 只是将数据保存起来，不切断血缘依赖；Checkpoint 切断血缘依赖。</li>
<li>Cache 缓存的数据通常存储在磁盘、内存等地方，可靠性低；Checkpoint 的数据通常存储在 HDFS 等容错、高可用的文件系统，可靠性高。</li>
</ul>
<p>建议对 checkpoint 的 RDD 使用 Cache 缓存，这样 checkpoint 的 job 只需从 Cache 缓存中读取数据，否则需要再从头计算一次。</p>
<h1 id="算子"><a href="#算子" class="headerlink" title="算子"></a>算子</h1><h2 id="mapPartition"><a href="#mapPartition" class="headerlink" title="mapPartition"></a>mapPartition</h2><p>对 rdd 中的整个分区的迭代器进行操作。</p>
<h3 id="与-map-的比较"><a href="#与-map-的比较" class="headerlink" title="与 map 的比较"></a>与 map 的比较</h3><ul>
<li><p>map 是对 rdd 中的每一个元素进行操作。</p>
</li>
<li><p>如果在这一过程中需要频繁创建额外的对象，则性能更高，例如将 rdd 中的数据通过 jdbc 写入数据库，map 需要为每个元素创建一个链接而 mapPartition 只需要为每个分区创建一个链接。</p>
</li>
<li><p>如果分区中数据量较大，容易导致内存不足。</p>
</li>
</ul>
<h2 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h2><p>将数据集中重复的数据去重。</p>
<h3 id="替代实现"><a href="#替代实现" class="headerlink" title="替代实现"></a>替代实现</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map(x =&gt; (x, <span class="literal">null</span>)).reduceByKey((x, *) =&gt; x, numPartitions).map(*._1)</span><br></pre></td></tr></table></figure>

<h2 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h2><p>可以将 rdd 按照相同的 Key 对 Value 进行聚合。</p>
<h3 id="与-groupByKey-的比较"><a href="#与-groupByKey-的比较" class="headerlink" title="与 groupByKey 的比较"></a>与 groupByKey 的比较</h3><ul>
<li>从 shuffle 的角度：reduceByKey 和 groupByKey 都存在 shuffle 的操作，但是 reduceByKey 可以在 shuffle 前对分区内相同 key 的数据进行预聚合（combine）功能，这样会写入磁盘数据量；而 groupByKey 只是进行分组，不存在数据量减少的问题，reduceByKey 性能比较高。</li>
<li>从功能的角度：reduceByKey 其实包含分组和聚合的功能。GroupByKey 只能分组，不能聚合。</li>
</ul>
<h3 id="与其他聚合函数的比较"><a href="#与其他聚合函数的比较" class="headerlink" title="与其他聚合函数的比较"></a>与其他聚合函数的比较</h3><ul>
<li>reduceByKey: 相同 key 的第一个数据不进行任何计算，分区内和分区间计算规则相同。</li>
<li>foldByKey: 相同 key 的第一个数据和初始值进行分区内计算，分区内和分区间计算规则相同。</li>
<li>aggregateByKey：相同 key 的第一个数据和初始值进行分区内计算，分区内和分区间计算规则可以不相同。</li>
<li>combineByKey：当计算过程中发现数据结构不满足要求时，可以让第一个数据转换结构，分区内和分区间计算规则不相同。</li>
</ul>
<h1 id="累加器"><a href="#累加器" class="headerlink" title="累加器"></a>累加器</h1><ul>
<li>用来把 Executor 端变量信息聚合到 Driver 端。</li>
</ul>
<p>在 Driver 程序中定义变量，在 Executor 端的每个 Task 都会得到这个变量的一份新的副本。</p>
<p>每个 task 更新这些副本的值后， 传回 Driver 端进行 merge 操作。</p>
<h1 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h1><ul>
<li>用来高效分发较大的对象。</li>
</ul>
<p>向所有工作节点发送一个较大的只读变量，以供一个或多个 Spark 操作使用。</p>
<p>如果在多个并行操作中使用同一个变量，Spark 会为每个任务<strong>分别发送</strong>。</p>
<h1 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h1><p>总体来说分两路：Stage 级与 Task 级。</p>
<ul>
<li>Job 以 Action 方法为界，遇到一个 Action 方法则触发一个 Job；</li>
<li>Stage 是 Job 的子集，以 RDD 宽依赖（即 Shuffle）为界，遇到 Shuffle 做一次划分；</li>
<li>Task 是 Stage 的子集，以并行度（分区数）来衡量，分区数是多少，则有多少个 task。</li>
</ul>
<h2 id="架构-1"><a href="#架构-1" class="headerlink" title="架构"></a>架构</h2><h3 id="DAGScheduler"><a href="#DAGScheduler" class="headerlink" title="DAGScheduler"></a>DAGScheduler</h3><p>负责 Stage 级的调度，主要是将 job 切分成若干 Stages，并将每个 Stage 打包成 TaskSet 交给 TaskScheduler 调度。</p>
<h3 id="TaskScheduler"><a href="#TaskScheduler" class="headerlink" title="TaskScheduler"></a>TaskScheduler</h3><p>负责 Task 级的调度，将 DAGScheduler 给过来的 TaskSet 按照指定的调度策略分发到 Executor 上执行，调度过程中 SchedulerBackend 负责提供可用资源。</p>
<p>监控 Stage 的运行状态，只有 Executor 丢失或者 Task 由于 Fetch 失败才需要重新提交失败的 Stage 以调度运行失败的任务，其他类型的 Task 失败会在 TaskScheduler 的调度过程中重试。</p>
<h3 id="SchedulerBackend"><a href="#SchedulerBackend" class="headerlink" title="SchedulerBackend"></a>SchedulerBackend</h3><p>通过 ApplicationMaster 申请资源</p>
<p>接收 Executor 的注册信息，并维护 Executor 的状态</p>
<p>不断从 TaskScheduler 中拿到合适的 Task 分发到 Executor 执行。</p>
<h3 id="HeartbeatReceiver"><a href="#HeartbeatReceiver" class="headerlink" title="HeartbeatReceiver"></a>HeartbeatReceiver</h3><p>负责接收 Executor 的心跳信息，监控 Executor 的存活状况，并通知到 TaskScheduler。</p>
<h3 id="TaskSetManager"><a href="#TaskSetManager" class="headerlink" title="TaskSetManager"></a>TaskSetManager</h3><p>负责监控管理同一个 Stage 中的 Task，TaskScheduler 以 TaskSetManager 为单元来调度任务。</p>
<h2 id="Stage-级调度"><a href="#Stage-级调度" class="headerlink" title="Stage 级调度"></a>Stage 级调度</h2><p>从 DAG 切割开始，主要是由 DAGScheduler 来完成。当遇到一个 Action 操作后就会触发一个 Job 的计算，并交给 DAGScheduler 来提交。</p>
<p>DAGScheduler 会根据 DAG 进行切分，将一个 Job 划分为若干 Stages，具体划分策略是，由最终的 RDD 不断通过依赖回溯判断父依赖是否是宽依赖，即以 Shuffle 为界，划分 Stage，窄依赖的 RDD 会被划分到同一个 Stage 中。</p>
<p>划分的 Stages 分两类，一类叫做 ResultStage，为 DAG 最下游的 Stage，由 Action 方法决定；另一类叫做 ShuffleMapStage，为下游 Stage 准备数据。</p>
<p>一个 Stage 是否被提交，需要判断它的父 Stage 是否执行，只有其父 Stage 执行完毕才能提交当前 Stage。如果一个 Stage 没有父 Stage，那么从该 Stage 开始提交。</p>
<p>Stage 提交时会将 Task 信息（分区信息以及方法等）序列化并打包成 TaskSet 交给 TaskScheduler。</p>
<h2 id="Task-级调度"><a href="#Task-级调度" class="headerlink" title="Task 级调度"></a>Task 级调度</h2><p>DAGScheduler 将 Stage 打包到交给 TaskScheduler 后，TaskScheduler 会将 TaskSet 封装为 TaskSetManager 加入到调度队列中，TaskScheduler 以 TaskSetManager 为单元来调度任务，TaskScheduler 会从调度队列中按照指定的调度策略选择 TaskSetManager 去调度运行。</p>
<h2 id="调度策略"><a href="#调度策略" class="headerlink" title="调度策略"></a>调度策略</h2><h3 id="FIFO"><a href="#FIFO" class="headerlink" title="FIFO"></a>FIFO</h3><h3 id="FAIR"><a href="#FAIR" class="headerlink" title="FAIR"></a>FAIR</h3><p>有一个 rootPool 和多个子 Pool，各个子 Pool 中存储着所有待分配的 TaskSetMagager，需要先对子 Pool 进行排序，再对子 Pool 里面的 TaskSetMagager 进行排序，因为 Pool 和 TaskSetMagager 都继承了 Schedulable 特质，因此使用相同的排序算法。 </p>
<p>基于 Fair-share 比较，每个要排序的对象包含三个属性: <code>runningTasks</code>（正在运行的 Task 数）、<code>minShare</code>、<code>weight</code></p>
<h4 id="参数设置-1"><a href="#参数设置-1" class="headerlink" title="参数设置"></a>参数设置</h4><ul>
<li><code>fairscheduler.xml</code> 配置文件</li>
</ul>
<h4 id="比较过程"><a href="#比较过程" class="headerlink" title="比较过程"></a>比较过程</h4><ol>
<li>runningTasks 比 minShare 小的先执行</li>
<li>minShare 使用率低的先执行</li>
<li>权重使用率（runningTasks 与 weight 的比值）低的先执行</li>
<li>名字</li>
</ol>
<p>整体上来说就是通过 minShare 和 weight 这两个参数控制比较过程，可以做到让 minShare 使用率和权重使用率少（实际运行 task 比例较少）的先运行。 </p>
<p>排序完成后，所有的 TaskSetManager 被放入一个 ArrayBuffer 里，之后依次被取出并发送给 Executor 执行。</p>
<h3 id="失败重试"><a href="#失败重试" class="headerlink" title="失败重试"></a>失败重试</h3><p>Task 被提交到 Executor 启动执行后，Executor 会将执行状态上报给 SchedulerBackend，SchedulerBackend 则告诉 TaskScheduler，TaskScheduler 找到该 Task 对应的 TaskSetManager，并通知到该 TaskSetManager，这样 TaskSetManager 就知道 Task 的失败与成功状态。</p>
<p>对于失败的 Task，会记录它失败的次数，如果失败次数还没有超过最大重试次数，那么就把它放回待调度的 Task 池子中，否则整个 Application 失败。</p>
<h3 id="黑名单"><a href="#黑名单" class="headerlink" title="黑名单"></a>黑名单</h3><p>在记录 Task 失败次数过程中，会记录它上一次失败所在的 ExecutorId 和 Host，这样下次再调度这个 Task 时，会避免其被调度到上一次失败的节点上，起到一定的容错作用。黑名单记录还包含了其对应的“拉黑”时间，及这段时间内不再往这个节点上调度该 Task。</p>
<h1 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h1><p>数据倾斜就是我们在计算数据的时候，数据的分散度不够，导致大量的数据集中到了一台或者几台机器上计算，这些数据的计算速度远远低于平均计算速度，导致整个计算过程过慢。 </p>
<ul>
<li>key 分布不均匀</li>
<li>业务数据本身的特性</li>
<li>建表时考虑不周</li>
<li>某些 SQL 语句本身就有数据倾斜</li>
</ul>
<h1 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h1><p><strong>增加jvm</strong>（Java Virtual Machine：Java虚拟机）内存，这适用于变量值非常少的情况，这种情况下，往往只能通过硬件的手段来进行调优，增加jvm内存可以显著的提高运行效率；</p>
<p><strong>增加reduce的个数</strong>，这适用于变量值非常多的情况，这种情况下最容易造成的结果就是大量相同key被partition到一个分区，从而一个reduce执行了大量的工作；</p>
<p><strong>重新设计key</strong>，有一种方案是在map阶段时给key加上一个随机数，有了随机数的key就不会被大量的分配到同一节点(小几率)，待到reduce后再把随机数去掉即可；</p>
<p><strong>使用combiner合并</strong>。combinner是在map阶段，reduce之前的一个中间阶段，在这个阶段可以选择性的把大量的相同key数据先进行一个合并，可以看做是local reduce，然后再交给reduce来处理，减轻了map端向reduce端发送的数据量(减轻了网络带宽)，也减轻了map端和reduce端中间的shuffle阶段的数据拉取数量(本地化磁盘IO速率)；（hive.map.aggr&#x3D;true）</p>
<p><strong>设置合理的map reduce的task数</strong>，能有效提升性能。（比如，10w+级别的计算，用160个reduce，那是相当的浪费，1个足够）；</p>
<p>数据量较大的情况下，**慎用count(distinct)**，count(distinct)容易产生倾斜问题；</p>
<p><strong>hive.groupby.skewindata&#x3D;true</strong>，有数据倾斜的时候进行负载均衡，当选项设定为 true，生成的查询计划会有两个 MR Job。第一个 MR Job 中，Map 的输出结果集合会随机分布到 Reduce 中，每个 Reduce 做部分聚合操作，并输出结果，这样处理的结果是相同的 Group By Key 有可能被分发到不同的 Reduce 中，从而达到负载均衡的目的；第二个 MR Job 再根据预处理的数据结果按照 Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成最终的聚合操作。</p>
<h1 id="留存计算"><a href="#留存计算" class="headerlink" title="留存计算"></a>留存计算</h1><p>用户在某段时间内开始使用应用，经过一段时间后，仍然继续使用该应用的用户，被认作是留存用户，这部分用户占当时新增用户的比例即是留存率，会按照每隔1单位时间（例日、周、月）来进行统计。</p>
<p>留存指的就是“有多少用户留下来了”。留存用户和留存率体现了应用的质量和保留用户的能力。</p>
<p>N日留存率&#x3D;某日新增且过N日还登录的用户数 &#x2F; 某日新增的用户数*100% </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    aa.dayno 日期,</span><br><span class="line">    aa.活跃用户数,</span><br><span class="line">    aa.次日留存用户数,</span><br><span class="line">    aa.三日留存用户数,</span><br><span class="line">    aa.七日留存用户数, </span><br><span class="line">    concat(round(<span class="number">100</span> <span class="operator">*</span> 次日留存用户数<span class="operator">/</span>活跃用户数, <span class="number">2</span>), <span class="string">&#x27;%&#x27;</span>) 次日留存率,</span><br><span class="line">    concat(round(<span class="number">100</span> <span class="operator">*</span> 三日留存用户数<span class="operator">/</span>活跃用户数, <span class="number">2</span>), <span class="string">&#x27;%&#x27;</span>) 三日留存率,</span><br><span class="line">    concat(round(<span class="number">100</span> <span class="operator">*</span> 七日留存用户数<span class="operator">/</span>活跃用户数, <span class="number">2</span>), <span class="string">&#x27;%&#x27;</span>) 七日留存率</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">    <span class="keyword">select</span> </span><br><span class="line">        a.dayno 日期,</span><br><span class="line">        <span class="built_in">count</span>(<span class="keyword">distinct</span> a.uid) <span class="keyword">as</span> 活跃用户数,</span><br><span class="line">        <span class="built_in">count</span>(<span class="keyword">distinct</span> b.uid) <span class="keyword">as</span> 次日留存用户数,</span><br><span class="line">        <span class="built_in">count</span>(<span class="keyword">distinct</span> c.uid) <span class="keyword">as</span> 三日留存用户数,</span><br><span class="line">        <span class="built_in">count</span>(<span class="keyword">distinct</span> d.uid) <span class="keyword">as</span> 七日留存用户数</span><br><span class="line">    <span class="keyword">from</span> act_user_info a</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> act_user_info b <span class="keyword">on</span> a.uid <span class="operator">=</span> b.uid <span class="keyword">and</span> b.dayno <span class="operator">=</span> date_add(a.dayno, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> act_user_info c <span class="keyword">on</span> a.uid <span class="operator">=</span> c.uid <span class="keyword">and</span> c.dayno <span class="operator">=</span> date_add(a.dayno, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">left</span> <span class="keyword">join</span> act_user_info d <span class="keyword">on</span> a.uid <span class="operator">=</span> d.uid <span class="keyword">and</span> d.dayno <span class="operator">=</span> date_add(a.dayno, <span class="number">7</span>)</span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> a.dayno</span><br><span class="line">) aa;</span><br></pre></td></tr></table></figure>

<h1 id="透视（Pviot）"><a href="#透视（Pviot）" class="headerlink" title="透视（Pviot）"></a>透视（Pviot）</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.groupBy(<span class="string">&quot;year&quot;</span>)</span><br><span class="line">	.pivot(<span class="string">&quot;month&quot;</span>)</span><br><span class="line">  .sum(<span class="string">&quot;num&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">xxx</span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">table_test</span><br><span class="line">PIVOT(</span><br><span class="line">	聚合函数(num) </span><br><span class="line">  <span class="keyword">FOR</span> <span class="keyword">month</span> <span class="keyword">in</span> (<span class="operator">&lt;</span>month_list<span class="operator">&gt;</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h1 id="逆透视"><a href="#逆透视" class="headerlink" title="逆透视"></a>逆透视</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">unpivot_df =  df_pivot.selectExpr(<span class="string">&quot;`年月`&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;stack(4, &#x27;项目1&#x27;, `项目1`,&#x27;项目2&#x27;, `项目2`, &#x27;项目3&#x27;, `项目3`, &#x27;项目x&#x27;, `项目x`) as (`项目`,`收入`)&quot;</span>) \</span><br><span class="line">        .<span class="built_in">filter</span>(<span class="string">&quot;`收入` &gt; 0 &quot;</span>) \</span><br><span class="line">        .orderBy([<span class="string">&quot;`年月`&quot;</span>, <span class="string">&quot;`项目`&quot;</span>]) \</span><br><span class="line">unpivot_df.show()</span><br></pre></td></tr></table></figure>

<h1 id="一行拆分多行"><a href="#一行拆分多行" class="headerlink" title="一行拆分多行"></a>一行拆分多行</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.withColumn(<span class="string">&quot;name&quot;</span>, explode(split($<span class="string">&quot;name&quot;</span>, <span class="string">&quot;[ ]&quot;</span>)))</span><br></pre></td></tr></table></figure>

<h1 id="分组聚合"><a href="#分组聚合" class="headerlink" title="分组聚合"></a>分组聚合</h1><ul>
<li><p>reduceByKey，合并具有相同键的值</p>
</li>
<li><p>groupByKey，对具有相同键的值进行分组</p>
</li>
<li><p>combineByKey，使用不同的返回类型合并具有相同键的值</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">combineByKey(</span><br><span class="line">	createCombiner,</span><br><span class="line">	mergeValue,</span><br><span class="line">	mergeCombiners,</span><br><span class="line">	partitioner</span><br><span class="line">)</span><br><span class="line"><span class="keyword">val</span> res2 = res.combineByKey(</span><br><span class="line">  (v) =&gt; (v, <span class="number">1</span>),</span><br><span class="line">  (acc: (<span class="type">Int</span>, <span class="type">Int</span>), v) =&gt; (acc._1 + v, acc._2 + <span class="number">1</span>),</span><br><span class="line">  (acc1: (<span class="type">Int</span>, <span class="type">Int</span>), acc2: (<span class="type">Int</span>, <span class="type">Int</span>)) =&gt; (acc1._1 + acc2._1, acc1._2 + acc2._2)</span><br><span class="line">).map&#123; <span class="keyword">case</span> (key, (sum, count)) =&gt; (key, sum / count.toFloat)&#125;</span><br><span class="line">res2.collectAsMap().foreach(println)</span><br></pre></td></tr></table></figure>

<ul>
<li>aggregation，与reduce()相似，但输入值和返回值的类型可以不一致</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">aggregate(zeroValue)</span><br><span class="line">(seqOp, combOp)</span><br><span class="line"><span class="keyword">val</span> res = input.aggregate((<span class="number">0</span>, <span class="number">0</span>))(</span><br><span class="line">	(acc, value) =&gt; (acc._1 + value, acc._2 + value),</span><br><span class="line">	(acc1, acc2) =&gt; (acc1._1 + acc2._1, acc1._2 + acc2._2))</span><br><span class="line"><span class="keyword">val</span> avg = res._1 / res._2.toDouble</span><br></pre></td></tr></table></figure>

<h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><ul>
<li>sortByKey</li>
<li>sortBy</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sortBy</span></span>[<span class="type">K</span>](</span><br><span class="line">    f: (<span class="type">T</span>) =&gt; <span class="type">K</span>,</span><br><span class="line">    ascending: <span class="type">Boolean</span> = <span class="literal">true</span>,</span><br><span class="line">    numPartitions: <span class="type">Int</span> = <span class="keyword">this</span>.partitions.size)</span><br><span class="line">    (<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">K</span>], ctag: <span class="type">ClassTag</span>[<span class="type">K</span>]): <span class="type">RDD</span>[<span class="type">T</span>] =</span><br><span class="line">  <span class="keyword">this</span>.keyBy[<span class="type">K</span>](f)</span><br><span class="line">      .sortByKey(ascending, numPartitions)</span><br><span class="line">      .values</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">keyBy</span></span>[<span class="type">K</span>](f: <span class="type">T</span> =&gt; <span class="type">K</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">T</span>)] = withScope &#123;  </span><br><span class="line">  <span class="keyword">val</span> cleanedF = sc.clean(f)  </span><br><span class="line">  map(x =&gt; (cleanedF(x), x))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">input.sortBy(x =&gt; x)</span><br></pre></td></tr></table></figure>

<ul>
<li>自定义类<ol>
<li>继承Ordered类，重写compare方法</li>
<li>序列化</li>
<li>重写toString(可选，主要为了可以展示数据)</li>
</ol>
</li>
<li>implicit</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">implicit</span> <span class="keyword">val</span> sortIntegersByString = <span class="keyword">new</span> <span class="type">Ordering</span>[<span class="type">Int</span>] &#123;</span><br><span class="line">	<span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compare</span></span>(a: <span class="type">Int</span>, b: <span class="type">Int</span>) = a.toString.compare(b.<span class="type">String</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h1><p>ROW ，以行的方式进行偏移，然后确定边界范围。</p>
<p>RANGE ，以逻辑的方式进行偏移，然后再确定边界范围。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&lt;</span>窗口函数<span class="operator">&gt;</span> <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> <span class="operator">&lt;</span>用于分组的列名<span class="operator">&gt;</span></span><br><span class="line">                <span class="keyword">order</span> <span class="keyword">by</span> <span class="operator">&lt;</span>用于排序的列名<span class="operator">&gt;</span>[<span class="keyword">ASC</span><span class="operator">/</span><span class="keyword">DESC</span>]</span><br><span class="line">                [frame_type] <span class="keyword">BETWEEN</span> [<span class="keyword">start</span>] <span class="keyword">AND</span> [<span class="keyword">end</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol>
<li>排名函数(ranking function) 包括rank，dense_rank， row_number，percent_rank， ntile等，后面我们结合例子来看。</li>
<li>分析函数 (analytic functions) 包括cume_dist，lag等。</li>
<li>聚合函数(aggregate functions)，就是我们常用的max, min, sum, avg等。</li>
</ol>
<h1 id="UDF"><a href="#UDF" class="headerlink" title="UDF"></a>UDF</h1><p>UDF：User-Defined-Function，用户自定义函数，数据是一进一出，功能类似于大多数数学函数或者字符串处理函数；</p>
<p>UDAF：User-Defined Aggregation Function，用户自定义聚合函数，数据是多进一出，功能类似于 count&#x2F;max&#x2F;min；</p>
<p>UDTF：User-Defined Table-Generating Functions，用户自定义表生成函数，数据是一进多出，功能类似于lateral view explore()；</p>
<h3 id="匿名注册"><a href="#匿名注册" class="headerlink" title="匿名注册"></a>匿名注册</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spark.udf.register(<span class="string">&quot;prefixName&quot;</span>, (name:<span class="type">String</span>)=&gt; &#123;</span><br><span class="line">  <span class="string">&quot;Name: &quot;</span> + name</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">spark.sql(<span class="string">&quot;select age, prefixName(name) from user&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="实名注册"><a href="#实名注册" class="headerlink" title="实名注册"></a>实名注册</h3><p>定义时要在后面加“ _”(注意前面有个空格) 。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isAdult</span></span>(age: <span class="type">Int</span>) = &#123;</span><br><span class="line">  <span class="keyword">if</span> (age &lt; <span class="number">18</span>) &#123;</span><br><span class="line">    <span class="literal">false</span></span><br><span class="line">  &#125; </span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">spark.udf.register(<span class="string">&quot;isAdult&quot;</span>, isAdult _)</span><br></pre></td></tr></table></figure>

<h3 id="临时UDF"><a href="#临时UDF" class="headerlink" title="临时UDF"></a>临时UDF</h3><p>在org.apache.spark.sql.execution.command.CreateFunctionCommand类的run方法中，会判断创建的Function是否是临时方法，若是，则会创建一个临时Function。</p>
<p>临时函数直接注册到functionRegistry(实现类是SimpleFunctionRegistry)，即内存中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTempFunction</span></span>(</span><br><span class="line">    name: <span class="type">String</span>,</span><br><span class="line">    info: <span class="type">ExpressionInfo</span>,</span><br><span class="line">    funcDefinition: <span class="type">FunctionBuilder</span>,</span><br><span class="line">    ignoreIfExists: <span class="type">Boolean</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">if</span> (functionRegistry.lookupFunctionBuilder(name).isDefined &amp;&amp; !ignoreIfExists) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">TempFunctionAlreadyExistsException</span>(name)</span><br><span class="line">  &#125;</span><br><span class="line">  functionRegistry.registerFunction(name, info, funcDefinition)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="持久化UDF"><a href="#持久化UDF" class="headerlink" title="持久化UDF"></a>持久化UDF</h3><p>在org.apache.spark.sql.execution.command.CreateFunctionCommand中，会调用SessionCatalog的createFunction，最终执行了HiveExternalCatalog的createFunction。</p>
<p>创建永久函数会在Hive元数据库中创建相应的函数。</p>
<p>在解析SQL中的UDF时，会调用SessionCatalog的lookupFunction0方法，在此方法中，首先会检查内存中是否存在，如果不存在则会加载此UDF，加载时会把RESOURCE_URI发到ClassLoader的路径中，如果把UDF注册到内存的functionRegistry中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lookupFunction</span></span>(</span><br><span class="line">    name: <span class="type">FunctionIdentifier</span>,</span><br><span class="line">    children: <span class="type">Seq</span>[<span class="type">Expression</span>]): <span class="type">Expression</span> = synchronized &#123;</span><br><span class="line">  <span class="comment">// Note: the implementation of this function is a little bit convoluted.</span></span><br><span class="line">  <span class="comment">// We probably shouldn&#x27;t use a single FunctionRegistry to register all three kinds of functions</span></span><br><span class="line">  <span class="comment">// (built-in, temp, and external).</span></span><br><span class="line">  <span class="keyword">if</span> (name.database.isEmpty &amp;&amp; functionRegistry.functionExists(name.funcName)) &#123;</span><br><span class="line">    <span class="comment">// This function has been already loaded into the function registry.</span></span><br><span class="line">    <span class="keyword">return</span> functionRegistry.lookupFunction(name.funcName, children)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If the name itself is not qualified, add the current database to it.</span></span><br><span class="line">  <span class="keyword">val</span> database = name.database.orElse(<span class="type">Some</span>(currentDb)).map(formatDatabaseName)</span><br><span class="line">  <span class="keyword">val</span> qualifiedName = name.copy(database = database)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (functionRegistry.functionExists(qualifiedName.unquotedString)) &#123;</span><br><span class="line">    <span class="comment">// This function has been already loaded into the function registry.</span></span><br><span class="line">    <span class="comment">// Unlike the above block, we find this function by using the qualified name.</span></span><br><span class="line">    <span class="keyword">return</span> functionRegistry.lookupFunction(qualifiedName.unquotedString, children)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The function has not been loaded to the function registry, which means</span></span><br><span class="line">  <span class="comment">// that the function is a permanent function (if it actually has been registered</span></span><br><span class="line">  <span class="comment">// in the metastore). We need to first put the function in the FunctionRegistry.</span></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> why not just check whether the function exists first?</span></span><br><span class="line">  <span class="keyword">val</span> catalogFunction = <span class="keyword">try</span> &#123;</span><br><span class="line">    externalCatalog.getFunction(currentDb, name.funcName)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">AnalysisException</span> =&gt; failFunctionLookup(name.funcName)</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">NoSuchPermanentFunctionException</span> =&gt; failFunctionLookup(name.funcName)</span><br><span class="line">  &#125;</span><br><span class="line">  loadFunctionResources(catalogFunction.resources)</span><br><span class="line">  <span class="comment">// Please note that qualifiedName is provided by the user. However,</span></span><br><span class="line">  <span class="comment">// catalogFunction.identifier.unquotedString is returned by the underlying</span></span><br><span class="line">  <span class="comment">// catalog. So, it is possible that qualifiedName is not exactly the same as</span></span><br><span class="line">  <span class="comment">// catalogFunction.identifier.unquotedString (difference is on case-sensitivity).</span></span><br><span class="line">  <span class="comment">// At here, we preserve the input from the user.</span></span><br><span class="line">  <span class="keyword">val</span> info = <span class="keyword">new</span> <span class="type">ExpressionInfo</span>(catalogFunction.className, qualifiedName.unquotedString)</span><br><span class="line">  <span class="keyword">val</span> builder = makeFunctionBuilder(qualifiedName.unquotedString, catalogFunction.className)</span><br><span class="line">  createTempFunction(qualifiedName.unquotedString, info, builder, ignoreIfExists = <span class="literal">false</span>)</span><br><span class="line">  <span class="comment">// Now, we need to create the Expression.</span></span><br><span class="line">  functionRegistry.lookupFunction(qualifiedName.unquotedString, children)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="followme">
  <span>Welcome to my other publishing channels</span>

  <div class="social-list">

      <div class="social-item">
        <a target="_blank" class="social-link" href="/atom.xml">
          <span class="icon">
            <i class="fa fa-rss"></i>
          </span>

          <span class="label">RSS</span>
        </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/Internship-Experience/" rel="tag"># Internship Experience</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/post/df2849ec.html" rel="prev" title="Java">
                  <i class="fa fa-chevron-left"></i> Java
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/post/2bcbefa4.html" rel="next" title="Data Warehouse">
                  Data Warehouse <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      <div class="tabs tabs-comment">
        <ul class="nav-tabs">
            <li class="tab"><a href="#comment-gitalk">gitalk</a></li>
            <li class="tab"><a href="#comment-waline">waline</a></li>
        </ul>
        <div class="tab-content">
            <div class="tab-pane gitalk" id="comment-gitalk">
              <div class="comments gitalk-container"></div>
            </div>
            <div class="tab-pane waline" id="comment-waline">
              <div class="comments" id="waline-comments"></div>
            </div>
        </div>
      </div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">浙ICP备19041488号-1 </a>
      <img src="/images/beian.png" alt="">
  </div>

<div class="copyright">
  &copy; 2021.9 – 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chris Gray</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="Symbols count total">127k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">1:56</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-cn","enable":true,"serverURL":"blog-vercel-sage.vercel.app","placeholder":"Welcome to comment","avatar":"mm","pageSize":10,"visitor":true,"comment_count":false,"requiredFields":["nick"],"meta":["nick","mail"],"libUrl":"https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js","el":"#waline-comments","path":"/post/5cd2e029.html"}</script>
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() => 
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => {
    new Waline(CONFIG.waline);
  });
});
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"ChrisGray0626","repo":"ChrisGray0626.github.io","client_id":"3782c574efca31c084de","client_secret":"f19fd10391350acd5b62659efaf44a94781b39d2","admin_user":"ChrisGray0626","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"4cce7a44caa3fece82ad095b52ba4d98"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":200,"height":300,"hOffset":280},"mobile":{"show":true}});</script></body>
</html>
